{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The `electoral_votes` variable is a dictionary containing the number of Electoral College votes for each state. For example\n",
    "```\n",
    "  >>> electoral_votes['Indiana']\n",
    "  11\n",
    "```\n",
    "Data from [Wikipedia: United_States_Electoral_College](https://en.wikipedia.org/wiki/United_States_Electoral_College)\n",
    "\n",
    "The `survey_results` variable is a dictionary mapping from states to an array of survey results for each candidate. Each row in a survey results array represents one survey and each column represents one candidate. There are 4 columns, representing Clinton, Trump, Johnson, and Stein in that order. In the example below, Clinton got 340 votes in the first survey, Trump got 258, Johnson got 27, and Stein got 13.\n",
    "```\n",
    "  >>> survey_results['Indiana']\n",
    "  array([[340, 258,  27,  13],\n",
    "         [240, 155,   5,   5],\n",
    "         [235, 155,  50,  20],\n",
    "         [308, 266,  49,  35],\n",
    "         [222, 161,  80,  30]])\n",
    "```\n",
    "Data from [Wikipedia: Statewide opinion polling for the United States presidential election, 2016](https://en.wikipedia.org/wiki/Statewide_opinion_polling_for_the_United_States_presidential_election,_2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling 5 states with 38 electoral college votes\n"
     ]
    }
   ],
   "source": [
    "electoral_votes = {\n",
    "    'Alabama': 9,\n",
    "    'Alaska': 3,\n",
    "    'Arizona': 11,\n",
    "    'Arkansas': 6,\n",
    "    'Colorado': 9,\n",
    "}\n",
    "\n",
    "survey_results = {\n",
    "    'Alabama': np.array([], dtype=int).reshape(0, 4),\n",
    "    'Alaska': np.array([400 * np.array([.47, .43, .07, .03]), 500 * np.array([.36, .37, .07, .03]), 500 * np.array([.34, .37, .10, .02]), 660 * np.array([.31, .36, .18, .06])], dtype=int),\n",
    "    'Arizona': np.array([392 * np.array([.45, .47, .05, .02]), 550 * np.array([.39, .47, .04, .03]), 719 * np.array([.40, .45, .09, .03]), 769 * np.array([.44, .49, .05, .01]), 2229 * np.array([.45, .44, .07, .01]), 700 * np.array([.43, .47, .02, .02]), 550 * np.array([.41, .45, .03, .01]), 994 * np.array([.42, .44, .04, .01]), 550 * np.array([.40, .42, .05, .02]), 2385 * np.array([.48, .46, .05, .01]), 401 * np.array([.45, .46, .04, .01]), 550 * np.array([.41, .41, .05, .02]), 1538 * np.array([.39, .44, .06, .02]), 713 * np.array([.43, .38, .06, .01]), 400 * np.array([.39, .37, .08, .03]), 600 * np.array([.44, .42, .09, .01]), 718 * np.array([.42, .42, .05, .01]), 484 * np.array([.41, .46, .09, .01]), 649 * np.array([.38, .40, .12, .03])], dtype=int),\n",
    "    'Arkansas': np.array([463 * np.array([.33, .56, .04, .02]), 831 * np.array([.34, .55, .03, .01]), 600 * np.array([.29, .57, .05, .03])], dtype=int),\n",
    "    'Colorado': np.array([1150 * np.array([.45, .44, .05, .04]), 500 * np.array([.44, .38, .07, .02]), 550 * np.array([.39, .39, .05, .04]), 750 * np.array([.44, .41, .08, .04]), 685 * np.array([.45, .37, .10, .03]), 400 * np.array([.49, .38, .07, .03]), 602 * np.array([.44, .33, .10, .03]), 694 * np.array([.46, .40, .06, .02]), 784 * np.array([.41, .42, .13, .03]), 991 * np.array([.40, .39, .07, .02]), 644 * np.array([.44, .42, .10, .02]), 540 * np.array([.41, .34, .12, .03]), 600 * np.array([.38, .42, .13, .02]), 704 * np.array([.48, .43, .04, .02]), 605 * np.array([.43, .38, .07, .02]), 997 * np.array([.42, .39, .07, .02])], dtype=int),\n",
    "}\n",
    "\n",
    "states = sorted(survey_results.keys())\n",
    "print 'Modeling', len(states), 'states with', sum(electoral_votes[s] for s in states), 'electoral college votes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative model\n",
    "\n",
    "1. For each state we generate an $\\vec{\\alpha}$ vector, which defines a Dirichlet distribution over the proportion of votes that go to each of the 4 candidates whenever we do a survey â€” including the final survey, namely the election itself which we want to predict. The prior over each component of $\\vec{\\alpha}$ is taken as a Cauchy distribution with location 0 and scale 1. Since the components of $\\vec{\\alpha}$ are positive, we actually use the positive half-Cauchy distribution.\n",
    "\n",
    "2. For each survey in a state we generate a probability vector $\\vec{p_i} \\sim \\text{Dirichlet}(\\vec{\\alpha})$ for the probability that a voter selects each of the 4 candidates.\n",
    "\n",
    "3. For each survey, we then generate the number of votes going to each candidate as $\\vec{k_i} \\sim \\text{Multinomial}(\\vec{p_i})$.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* Use Stan to sample from the posterior distribution over $\\alpha$ and visualize your results. There are 10 states, so you will have 10 posteriors.\n",
    "* The posteriors over $\\alpha$ show a lot of variation between different states. Explain the results you get in terms of the model and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_8f3004cabe1cb659a1b84d3acf11a32f NOW.\n"
     ]
    }
   ],
   "source": [
    "stan_code = '''\n",
    "data {\n",
    "int<lower=1> K;  // Number of candidates(categories)\n",
    "int<lower=0> N;  // Number of surveys\n",
    "real cauchy_loc;  // Hyperparameters for Cauchy\n",
    "real<lower=0> cauchy_scale;  // Hyperparameters for Cauchy\n",
    "int<lower=0> x[N,K];  // Survey results(observations)\n",
    "}\n",
    "\n",
    "parameters {\n",
    "vector[K] alpha;  // Concentration parameters for Dirichlet\n",
    "simplex[K] p[N];  // Probability parameters for Multinomial\n",
    "}\n",
    "\n",
    "model {\n",
    "for (i in 1:K) {\n",
    "    alpha[i] ~ cauchy(cauchy_loc, cauchy_scale);\n",
    "}\n",
    "for (i in 1:N) { // For each survey\n",
    "    p[i,:] ~ dirichlet(fabs(alpha));\n",
    "    x[i,:] ~ multinomial(p[i,:]);\n",
    "}\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1 of 4000 iterations saturated the maximum tree depth of 10 (0%)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_8f3004cabe1cb659a1b84d3acf11a32f.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[1]   0.17    0.48   9.79 -16.37   -1.1-4.8e-3   1.04   15.2  417.0   1.01\n",
      "alpha[2]  -0.24    0.37   8.05 -14.57  -1.06  -0.03   0.93  13.31  473.0   1.01\n",
      "alpha[3]  -0.09    0.31   8.51 -11.07  -1.02-1.9e-3   1.04  12.94  747.0    1.0\n",
      "alpha[4]   0.07    0.42  11.67  -14.8  -1.07 7.5e-4   1.06  16.61  786.0   1.01\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct 22 14:26:45 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "Arizona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter alpha[2] is 0.000542399973809!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[3] is 0.000543046108399!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[4] is 0.000532061968757!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter alpha[2] is 3.47994277689!\n",
      "WARNING:pystan:Rhat for parameter alpha[3] is 3.45514724376!\n",
      "WARNING:pystan:Rhat for parameter alpha[4] is 3.94123793791!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_8f3004cabe1cb659a1b84d3acf11a32f.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[1] -88.99    0.98  24.85 -147.6 -102.5 -85.63 -71.56 -49.95  644.0   1.01\n",
      "alpha[2]  46.97   56.88  83.79 -124.6  -2.09  79.38  100.3 150.56    2.0   3.48\n",
      "alpha[3]    5.9    7.52  11.08  -17.0   0.04  10.29  12.94  19.11    2.0   3.46\n",
      "alpha[4]   0.02     2.5   3.65  -5.32  -3.36  -0.05   3.42   5.34    2.0   3.94\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct 22 14:27:58 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "Arkansas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter alpha[1] is 0.000983382685621!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[3] is 0.00093634249897!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[4] is 0.000897395565006!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter alpha[1] is 1.47091208281!\n",
      "WARNING:pystan:Rhat for parameter alpha[2] is 1.15276663576!\n",
      "WARNING:pystan:Rhat for parameter alpha[3] is 1.50722913974!\n",
      "WARNING:pystan:Rhat for parameter alpha[4] is 1.53356553431!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:149 of 4000 iterations ended with a divergence (3%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING:pystan:4 of 4000 iterations saturated the maximum tree depth of 10 (0%)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_8f3004cabe1cb659a1b84d3acf11a32f.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[1]   1.93   16.03   31.8 -57.14 -14.65  -0.25  15.55  78.68    4.0   1.47\n",
      "alpha[2]  10.53    12.8  54.92 -94.74 -17.66  14.08  34.44 129.62   18.0   1.15\n",
      "alpha[3]  -0.13    2.07   4.01  -9.15  -2.06   0.02   1.94   7.58    4.0   1.51\n",
      "alpha[4]   0.72    1.01   1.91  -3.37 9.1e-3   0.88   1.55   4.65    4.0   1.53\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct 22 14:28:18 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "Alaska\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter alpha[1] is 0.000648731091084!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[2] is 0.000649362225424!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[3] is 0.00070189395102!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[4] is 0.000656199507573!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter alpha[1] is 2.06149007125!\n",
      "WARNING:pystan:Rhat for parameter alpha[2] is 2.05991157223!\n",
      "WARNING:pystan:Rhat for parameter alpha[3] is 1.84337702833!\n",
      "WARNING:pystan:Rhat for parameter alpha[4] is 2.00911447976!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:66 of 4000 iterations ended with a divergence (1%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_8f3004cabe1cb659a1b84d3acf11a32f.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[1]  -0.28    9.18  14.79 -26.87 -11.49  -0.02  10.59  27.63    3.0   2.06\n",
      "alpha[2]   0.03     9.6  15.48 -28.35  -11.6  -0.12  11.33  29.21    3.0   2.06\n",
      "alpha[3]   1.88    2.22   3.71  -5.85  -0.05   2.37   4.11   8.62    3.0   1.84\n",
      "alpha[4]  -0.76     0.9   1.47  -3.22  -1.65  -1.05   0.03    2.3    3.0   2.01\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct 22 14:28:29 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "Colorado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter for parameter alpha[1] is 0.000535793113315!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[2] is 0.00053628102861!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[3] is 0.000536350934701!\n",
      "WARNING:pystan:n_eff / iter for parameter alpha[4] is 0.000537676109031!\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat for parameter alpha[1] is 3.75942297852!\n",
      "WARNING:pystan:Rhat for parameter alpha[2] is 3.73717789995!\n",
      "WARNING:pystan:Rhat for parameter alpha[3] is 3.72350047042!\n",
      "WARNING:pystan:Rhat for parameter alpha[4] is 3.65483549318!\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_8f3004cabe1cb659a1b84d3acf11a32f.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[1]  -0.06   64.36  94.22 -140.7 -86.91  -1.41  87.21 135.87    2.0   3.76\n",
      "alpha[2]   0.25   58.59  85.82 -126.2 -79.21   2.19  79.81 127.12    2.0   3.74\n",
      "alpha[3]  -0.06   11.84  17.35 -25.97 -16.01  -0.85  15.89  25.34    2.0   3.72\n",
      "alpha[4] 7.7e-3    4.09    6.0  -8.94  -5.51   0.08   5.54   8.85    2.0   3.65\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct 22 14:29:45 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "for state, obs in survey_results.items():\n",
    "    data = {\n",
    "        'K':4,\n",
    "        'N':len(obs),\n",
    "        'cauchy_loc': 0.,\n",
    "        'cauchy_scale': 1.,\n",
    "        'x': obs\n",
    "    }\n",
    "    \n",
    "    print state\n",
    "    stan_output = stan_model.sampling(data=data)\n",
    "    summary = stan_output.stansummary(pars=['alpha'])\n",
    "    print summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation time\n",
    "\n",
    "Use the posterior samples to predict the outcome of the presidential elections.\n",
    "\n",
    "* Predict the probability that each candidate will win each state.\n",
    "   * Use the posterior $\\alpha$ samples to generate posterior predictive samples for $p$ â€” the proportion of votes each candidate would get in each state in an election.\n",
    "   * Use these $p$ samples to estimate the probability that each candidate will win each state.\n",
    "* Predict the probability that each candidate will win the presidential election.\n",
    "   * Use the posterior predictive probability that each candidate will win each state to generate samples over the total number Electoral College votes each candidate would get in an election.\n",
    "   * Use the total number of votes to generate samples over who would win the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
